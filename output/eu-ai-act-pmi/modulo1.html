<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Modulo 1: Panoramica rapida e timeline AI Act - EU AI Act: essentials e azioni pratiche per PMI</title>
    <link rel="stylesheet" href="styles.css">
    <script src="scorm_api.js"></script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Modulo 1: Panoramica rapida e timeline AI Act</h1>
            <div class="subtitle">EU AI Act: essentials e azioni pratiche per PMI</div>
            <div class="progress-indicator">20-25 minuti</div>
        </div>

        <div class="content">
            <h1>Modulo 1: Panoramica rapida e timeline AI Act</h1>

<strong>Durata:</strong> 20-25 minuti

<strong>Obiettivi del modulo:</strong>
<ul>
<li>Spiegare cos'√® l'EU AI Act e perch√© √® rilevante per le PMI italiane</li>
<li>Identificare le 4 categorie principali di sistemi AI secondo la normativa</li>
<li>Riconoscere le date chiave della timeline di applicazione (2025-2027)</li>
<li>Distinguere tra obblighi immediati e obblighi futuri per le PMI</li>
</ul>

<hr>

<h2>1.1 Introduzione all'EU AI Act</h2>

<h3>Cos'√® l'AI Act e perch√© esiste</h3>

L'<strong>EU AI Act</strong> √® la prima legge al mondo che regola l'intelligenza artificiale. √à entrata ufficialmente in vigore il 1¬∞ agosto 2024.

Perch√© nasce? L'AI offre enormi opportunit√†, ma porta anche rischi concreti. Decisioni automatizzate sbagliate possono discriminare persone, violare privacy, o compromettere la sicurezza. L'AI Act vuole bilanciare innovazione e protezione dei diritti fondamentali.

La legge si applica a chi <strong>fornisce</strong> sistemi AI (li sviluppa e vende) e a chi li <strong>usa</strong> (deployer). La maggior parte delle PMI italiane rientra nella seconda categoria: utilizzate AI, non la sviluppate.

<h3>Fornitori vs Deployer: dove ti collochi?</h3>

<strong>Fornitore:</strong> Sviluppi un software con AI e lo vendi a clienti. Esempio: una software house che crea un tool di analisi predittiva per e-commerce.

<strong>Deployer (utilizzatore):</strong> Usi strumenti AI sviluppati da altri per le tue attivit√† aziendali. Esempio: un'azienda manifatturiera che usa ChatGPT per scrivere report tecnici, oppure un negozio online che integra un chatbot per assistenza clienti.

<strong>La maggior parte delle PMI √® deployer.</strong> Questo significa che hai obblighi pi√π leggeri rispetto ai fornitori, ma comunque precisi e misurabili.

<h3>Quando una PMI "usa AI"?</h3>

Ecco alcuni esempi pratici di uso AI in una PMI italiana:

<strong>Esempio 1 - Marketing e comunicazione:</strong>
Una piccola azienda vinicola in Toscana usa ChatGPT per generare descrizioni prodotto sul sito e-commerce. Usa anche un chatbot per rispondere alle FAQ dei clienti. <strong>Classificazione:</strong> Deployer di sistemi a rischio limitato.

<strong>Esempio 2 - Risorse umane:</strong>
Uno studio di commercialisti a Milano usa un software AI per filtrare CV ricevuti per posizioni di stagista. Il sistema assegna un punteggio ai candidati basato su esperienza e competenze. <strong>Classificazione:</strong> Deployer di sistema ad alto rischio (perch√© impatta sul diritto al lavoro).

<strong>Esempio 3 - Controllo qualit√†:</strong>
Un'azienda manifatturiera di componentistica a Brescia usa AI per rilevare difetti visuali su pezzi meccanici. Il sistema segnala anomalie, ma l'operatore decide se scartare il pezzo. <strong>Classificazione:</strong> Deployer di sistema a rischio limitato o minimo (decisione finale umana).

<hr>

<h2>1.2 Le 4 categorie di sistemi AI</h2>

L'AI Act classifica i sistemi AI in <strong>4 livelli di rischio</strong>, ciascuno con obblighi diversi. Pi√π √® alto il rischio, pi√π stringenti sono i requisiti.

<h3>üî¥ Sistemi Proibiti (rischio inaccettabile)</h3>

Questi sistemi sono <strong>vietati</strong> perch√© violano diritti fondamentali. Non puoi usarli in nessun caso (salvo eccezioni per forze dell'ordine in contesti specifici).

<strong>Esempi di sistemi proibiti:</strong>
<ul>
<li><strong>Manipolazione comportamento:</strong> AI che sfrutta vulnerabilit√† psicologiche per influenzare scelte (es. app che manipola bambini a comportamenti pericolosi).</li>
<li><strong>Social scoring:</strong> Sistemi che assegnano punteggi sociali ai cittadini basati su comportamento o caratteristiche personali (stile Cina).</li>
<li><strong>Riconoscimento biometrico in tempo reale:</strong> Uso di riconoscimento facciale in spazi pubblici per sorveglianza di massa (con limitate eccezioni per polizia).</li>
</ul>

<strong>Per le PMI:</strong> √à molto improbabile che tu stia usando sistemi proibiti. Se usi tool standard (ChatGPT, Google AI, Microsoft Copilot), sei al sicuro.

<hr>

<h3>üü† Sistemi ad Alto Rischio</h3>

Questi sistemi <strong>impattano diritti fondamentali</strong> come lavoro, istruzione, accesso a servizi essenziali, o sicurezza. Hanno obblighi di conformit√† rigorosi.

<strong>Quando un sistema √® ad alto rischio?</strong>
<ul>
<li>Influisce su decisioni critiche per le persone (assunzioni, credito, accesso a servizi pubblici)</li>
<li>Opera in settori regolamentati (salute, trasporti, infrastrutture critiche)</li>
<li>Pu√≤ discriminare o violare privacy in modo grave</li>
</ul>

<strong>Esempi concreti per PMI italiane:</strong>

<table>
<thead>
<tr>
<th><strong>Settore</strong></th>
<th><strong>Caso d'uso AI</strong></th>
<th><strong>Perch√© √® alto rischio</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>HR</strong></td>
<td>Software screening CV per recruitment</td>
<td>Impatta diritto al lavoro; rischio bias discriminatori</td>
</tr>
<tr>
<td><strong>Finance</strong></td>
<td>Credit scoring automatizzato per prestiti clienti</td>
<td>Determina accesso a servizi finanziari essenziali</td>
</tr>
<tr>
<td><strong>Manifattura</strong></td>
<td>Sistema AI per valutazione performance operai</td>
<td>Influisce su stipendio, carriera, licenziamenti</td>
</tr>
<tr>
<td><strong>Retail</strong></td>
<td>AI per analisi comportamento clienti in negozio fisico</td>
<td>Raccolta dati biometrici (movimenti, espressioni)</td>
</tr>
</tbody>
</table>

<strong>Obblighi principali per sistemi ad alto rischio (deployer):</strong>
<ul>
<li><strong>Supervisione umana:</strong> Un operatore deve poter intervenire e correggere decisioni AI.</li>
<li><strong>Trasparenza:</strong> Informare le persone che l'AI √® coinvolta nella decisione.</li>
<li><strong>Documentazione:</strong> Tenere un registro dei sistemi AI usati e delle decisioni prese.</li>
<li><strong>Valutazione impatto:</strong> Condurre una DPIA (Data Protection Impact Assessment) prima di attivare il sistema.</li>
</ul>

<strong>Esempio pratico:</strong> Se usi un software per filtrare CV, devi assicurarti che un recruiter umano riveda sempre la shortlist prima di scartare candidati. E devi informare i candidati che un sistema AI ha partecipato alla selezione.

<hr>

<h3>üü° General Purpose AI (GPAI)</h3>

I <strong>GPAI</strong> sono modelli fondazionali di grandi dimensioni usabili per scopi multipli. Esempi: GPT-4 (OpenAI), Claude (Anthropic), Gemini (Google), Llama (Meta).

<strong>Per le PMI:</strong> Se usi ChatGPT, Microsoft Copilot, Google Bard, o altri tool basati su GPAI, <strong>non hai obblighi diretti come deployer</strong>. Gli obblighi ricadono sui fornitori (OpenAI, Google, Microsoft).

<strong>Eccezione:</strong> Se integri profondamente un GPAI in un sistema ad alto rischio (es. chatbot per credit scoring), allora devi seguire le regole per i sistemi ad alto rischio.

<strong>In sintesi:</strong> Usa tranquillamente ChatGPT per scrivere email o report interni. Fai attenzione se usi AI generativa per decisioni critiche su persone (HR, credito, valutazioni).

<hr>

<h3>üü¢ Sistemi a Rischio Limitato o Minimo</h3>

Questa categoria include la <strong>maggior parte degli usi AI nelle PMI</strong>: chatbot, tool di generazione contenuti, analisi dati interne, assistenti virtuali.

<strong>Obblighi principali (molto pi√π leggeri):</strong>
<ul>
<li><strong>Trasparenza:</strong> Devi informare gli utenti che stanno interagendo con un'AI o che un contenuto √® stato generato da AI.</li>
<li><strong>Watermark (quando possibile):</strong> Se generi immagini, video, o audio con AI, devi indicare che sono AI-generated.</li>
</ul>

<strong>Esempi pratici per PMI italiane:</strong>

<table>
<thead>
<tr>
<th><strong>Caso d'uso</strong></th>
<th><strong>Obbligo AI Act</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Chatbot su sito e-commerce</td>
<td>Avviso: "Stai parlando con un assistente virtuale"</td>
</tr>
<tr>
<td>Email marketing generate da ChatGPT</td>
<td>Non serve avviso (comunicazione interna/marketing)</td>
</tr>
<tr>
<td>Immagini prodotto create con Midjourney</td>
<td>Indicare "Immagine generata con AI" (se pubblicata)</td>
</tr>
<tr>
<td>Tool AI per previsioni vendite interne</td>
<td>Nessun obbligo (decisione interna, no impatto su terzi)</td>
</tr>
</tbody>
</table>

<strong>Esempio concreto:</strong> Hai un e-commerce di abbigliamento e usi un chatbot per rispondere alle FAQ. Sul widget del chatbot devi scrivere: "Ciao! Sono un assistente virtuale AI. Come posso aiutarti?" Oppure: "Questo servizio utilizza intelligenza artificiale."

<strong>Nota importante:</strong> Se il tuo chatbot raccoglie dati sensibili (es. dati sanitari, preferenze politiche) o influenza decisioni d'acquisto in modo ingannevole, potrebbe salire a rischio pi√π alto. Valuta caso per caso.

<hr>

<h2>1.3 Timeline cruciale 2025-2027</h2>

L'AI Act entra in vigore per fasi. Alcune regole sono gi√† attive, altre partiranno nei prossimi anni. Ecco le <strong>date chiave</strong> da segnare in agenda.

<table>
<thead>
<tr>
<th><strong>Data</strong></th>
<th><strong>Cosa entra in vigore</strong></th>
<th><strong>Chi riguarda</strong></th>
<th><strong>Azioni richieste</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>2 febbraio 2025</strong></td>
<td>Divieto sistemi proibiti</td>
<td>Tutti (fornitori e deployer)</td>
<td>Verificare di non usare AI proibite (manipolazione, social scoring, biometria di massa)</td>
</tr>
<tr>
<td><strong>2 agosto 2025</strong></td>
<td>Obblighi per fornitori GPAI</td>
<td>OpenAI, Google, Microsoft, Anthropic</td>
<td>Nessuna azione diretta per PMI deployer</td>
</tr>
<tr>
<td><strong>2 agosto 2026</strong></td>
<td>Obblighi per sistemi ad alto rischio</td>
<td><strong>PMI che usano AI per HR, credit scoring, valutazione lavoratori</strong></td>
<td>Implementare human oversight, trasparenza, DPIA, registri AI</td>
</tr>
<tr>
<td><strong>2 agosto 2027</strong></td>
<td>Piena applicazione per tutti</td>
<td>Tutti i deployer</td>
<td>Conformit√† completa: policy AI, registri, trasparenza, formazione</td>
</tr>
</tbody>
</table>

<h3>Data pi√π rilevante per le PMI: 2 agosto 2026</h3>

Se la tua azienda usa (o pianifica di usare) AI per <strong>recruitment, valutazione dipendenti, credit scoring, o decisioni automatizzate su persone</strong>, hai <strong>18 mesi da oggi</strong> per prepararti.

<strong>Cosa fare entro agosto 2026:</strong>
1. <strong>Mappare</strong> tutti i sistemi AI in uso (fai un inventario).
2. <strong>Classificare</strong> ciascun sistema nelle 4 categorie.
3. <strong>Implementare controlli</strong> per i sistemi ad alto rischio: supervisione umana, registro decisioni, trasparenza verso utenti.
4. <strong>Redigere una AI policy aziendale</strong> che definisce chi approva nuovi sistemi AI e come gestirli.
5. <strong>Formare il team</strong> (HR, IT, marketing, legal) su obblighi AI Act.

<strong>Nota pratica:</strong> Non aspettare l'ultimo momento. Molti fornitori di software AI stanno ancora aggiornando i loro tool per conformit√†. Inizia ora a fare domande ai tuoi vendor e a documentare l'uso interno.

<hr>

<h2>1.4 Implicazioni per funzione aziendale</h2>

L'AI Act non √® solo un problema del reparto IT o Legal. Ogni funzione aziendale che usa AI ha responsabilit√† specifiche. Ecco una guida pratica divisa per ruolo.

<h3>Marketing</h3>

<strong>Cosa cambia:</strong>
<ul>
<li>Se usi AI per generare contenuti (testi, immagini, video), devi indicare che sono AI-generated (watermark o disclaimer).</li>
<li>Se usi chatbot sul sito, devi avvisare l'utente che sta interagendo con un assistente virtuale.</li>
<li>Se usi AI per segmentazione clienti o pubblicit√† targetizzata, verifica che non ci siano bias discriminatori (es. escludere donne da offerte di lavoro).</li>
</ul>

<strong>Azioni concrete:</strong>
<ul>
<li>Aggiungi disclaimer sui chatbot: "Questo √® un assistente virtuale AI."</li>
<li>Etichetta contenuti AI-generated: "Immagine creata con AI" nelle descrizioni.</li>
<li>Documenta tool AI usati in un registro marketing (nome tool, funzione, fornitore).</li>
</ul>

<hr>

<h3>HR (Risorse Umane)</h3>

<strong>Cosa cambia:</strong>
<ul>
<li>L'uso di AI per recruitment √® <strong>alto rischio</strong>. Se usi software per screening CV o video-interviste automatizzate, hai obblighi pesanti.</li>
<li>Devi garantire <strong>human oversight</strong>: un recruiter umano deve rivedere tutte le decisioni AI prima di scartare candidati.</li>
<li>Devi <strong>informare i candidati</strong> che un sistema AI √® coinvolto nel processo di selezione.</li>
<li>Devi fare una <strong>valutazione d'impatto (DPIA)</strong> prima di usare il sistema.</li>
</ul>

<strong>Azioni concrete:</strong>
<ul>
<li>Chiedi al tuo fornitore software (es. LinkedIn Recruiter, Workday, sistemi ATS) documentazione sulla conformit√† AI Act.</li>
<li>Inserisci clausola nel processo recruiting: "Tutte le shortlist AI devono essere validate da un recruiter umano."</li>
<li>Informa i candidati nella job description o email di conferma candidatura: "Questo processo utilizza AI per screening iniziale, con validazione finale umana."</li>
</ul>

<hr>

<h3>Customer Service</h3>

<strong>Cosa cambia:</strong>
<ul>
<li>Chatbot e assistenti virtuali sono generalmente <strong>rischio limitato</strong>, con obbligo di trasparenza.</li>
<li>Se usi AI per scoring clienti (affidabilit√†, credit score, accesso a servizi premium), sale a <strong>alto rischio</strong>.</li>
</ul>

<strong>Azioni concrete:</strong>
<ul>
<li>Chatbot: Avviso chiaro all'utente ("Assistente virtuale AI").</li>
<li>Scoring/segmentazione: Verifica se influenza accesso a servizi essenziali. Se s√¨, implementa trasparenza e diritto a contestazione umana.</li>
<li>Documenta policy escalation: quando un cliente pu√≤ parlare con un operatore umano.</li>
</ul>

<hr>

<h3>IT e Data</h3>

<strong>Cosa cambia:</strong>
<ul>
<li>Sei il custode dei <strong>dataset</strong> usati per AI. Devi garantire qualit√†, rappresentativit√†, assenza di bias.</li>
<li>Devi mantenere un <strong>registro dei sistemi AI</strong> in uso aziendale (nome, fornitore, categoria rischio, funzione).</li>
<li>Devi implementare <strong>log</strong> per sistemi ad alto rischio (tracciare input/output/decisioni).</li>
</ul>

<strong>Azioni concrete:</strong>
<ul>
<li>Crea un file Excel "Registro AI aziendale" con colonne: Nome sistema, Fornitore, Funzione, Categoria rischio, Responsabile, Data attivazione.</li>
<li>Per sistemi ad alto rischio: Configura log automatici (chi ha usato il sistema, quando, quale decisione ha generato).</li>
<li>Audit periodico dataset: Verifica che i dati di training/input non contengano bias (es. solo CV maschili, solo clienti >50 anni).</li>
</ul>

<hr>

<h3>Legal e Compliance</h3>

<strong>Cosa cambia:</strong>
<ul>
<li>Devi redigere una <strong>AI policy aziendale</strong> che regola uso, approvazione, e governance AI.</li>
<li>Devi coordinare <strong>DPIA</strong> (valutazioni d'impatto) per sistemi ad alto rischio.</li>
<li>Devi negoziare <strong>clausole contrattuali AI Act</strong> con i fornitori (responsabilit√†, audit, supporto conformit√†).</li>
</ul>

<strong>Azioni concrete:</strong>
<ul>
<li>Redigi AI policy (1-2 pagine): principi etici, ruoli (chi approva nuovi tool AI), processo valutazione rischio, gestione incidenti.</li>
<li>Integra DPIA esistente (GDPR) con sezione AI-specific per sistemi ad alto rischio.</li>
<li>Rivedi contratti fornitori AI: Aggiungi clausola "Fornitore garantisce conformit√† AI Act e supporta PMI in DPIA/audit."</li>
</ul>

<hr>

<h2>Attivit√† Interattiva - Domanda Riflessiva</h2>

<strong>Prompt per il partecipante:</strong>

<blockquote><strong>Rifletti sulla tua funzione aziendale.</strong></blockquote>
>
<blockquote>Quali strumenti AI usi attualmente nel tuo lavoro quotidiano? (Es. ChatGPT, software HR, chatbot, tool analisi dati)</blockquote>
>
<blockquote>In base a quanto hai appreso in questo modulo, identifica <strong>almeno 1 implicazione concreta dell'AI Act</strong> per la tua funzione.</blockquote>
>
<blockquote>Esempi:</blockquote>
<blockquote>- "Lavoro in Marketing. Uso ChatGPT per scrivere post LinkedIn. Implicazione: devo indicare che i contenuti sono AI-generated se li pubblico a nome aziendale."</blockquote>
<blockquote>- "Lavoro in HR. Usiamo un software per filtrare CV. Implicazione: √® un sistema ad alto rischio, devo implementare human oversight e informare i candidati."</blockquote>
>
<blockquote><strong>Scrivi la tua risposta nel box sottostante (max 100 parole).</strong></blockquote>

<strong>Istruzioni:</strong>
Questa attivit√† non √® valutata, ma ti aiuta a contestualizzare l'AI Act nella tua realt√† lavorativa. Prenditi 3-5 minuti per riflettere e scrivere. Se stai seguendo il corso in gruppo, condividi la tua risposta in un forum o sessione di discussione.

<hr>

<h2>Quiz Formativo - Verifica Modulo 1</h2>

<strong>Istruzioni:</strong> Rispondi alle 6 domande seguenti. Riceverai feedback immediato dopo ogni risposta. Puoi riprovare quante volte vuoi. L'obiettivo √® verificare la comprensione, non valutarti.

<hr>

<h3>Domanda 1 di 6</h3>

<strong>Quale dei seguenti sistemi √® PROIBITO dall'AI Act?</strong>

<strong>Opzioni:</strong>
<ul>
<li>A) Un chatbot per assistenza clienti che informa gli utenti di essere AI</li>
<li>B) Un sistema di social scoring che valuta cittadini in base a comportamento sociale</li>
<li>C) Un software di recruitment che filtra CV con supervisione umana</li>
<li>D) Un tool AI per generare immagini di prodotto</li>
</ul>

<strong>Risposta corretta:</strong> B

<strong>Feedback risposta corretta:</strong>
<p>‚úì <strong>Corretto!</strong> Il social scoring √® vietato perch√© viola diritti fondamentali e dignit√† umana. √à uno dei sistemi proibiti dall'AI Act.</p>

<strong>Feedback risposta errata:</strong>
<p>‚úó <strong>Non corretto.</strong> Il social scoring (valutare persone con punteggi basati su comportamento) √® considerato inaccettabile e quindi proibito. Chatbot, recruitment con supervisione, e generazione immagini sono leciti con i giusti controlli. <strong>Rivedi sezione 1.2 - Sistemi Proibiti.</strong></p>

<hr>

<h3>Domanda 2 di 6</h3>

<strong>Una PMI che usa ChatGPT per scrivere email interne √® considerata:</strong>

<strong>Opzioni:</strong>
<ul>
<li>A) Fornitore di sistema AI</li>
<li>B) Deployer di sistema AI</li>
<li>C) Nessuna delle due (ChatGPT √® GPAI, nessun obbligo)</li>
<li>D) Soggetta a regole GPAI provider</li>
</ul>

<strong>Risposta corretta:</strong> B

<strong>Feedback risposta corretta:</strong>
<p>‚úì <strong>Esatto!</strong> La PMI √® <strong>deployer</strong> (utilizzatore) di ChatGPT. OpenAI √® il fornitore. Come deployer, hai obblighi leggeri (trasparenza se usi AI per decisioni su persone o contenuti pubblici).</p>

<strong>Feedback risposta errata:</strong>
<p>‚úó <strong>Non corretto.</strong> Una PMI che usa tool AI di terzi (ChatGPT, Copilot, etc.) √® <strong>deployer</strong>, non fornitore. I fornitori sono chi sviluppa e vende AI (OpenAI, Microsoft, Google). Come deployer, hai comunque obblighi (trasparenza, registro), ma pi√π leggeri rispetto ai fornitori. <strong>Rivedi sezione 1.1 - Fornitori vs Deployer.</strong></p>

<hr>

<h3>Domanda 3 di 6</h3>

<strong>Entro quale data le PMI devono conformarsi per i sistemi ad alto rischio?</strong>

<strong>Opzioni:</strong>
<ul>
<li>A) 2 febbraio 2025</li>
<li>B) 2 agosto 2025</li>
<li>C) 2 agosto 2026</li>
<li>D) 2 agosto 2027</li>
</ul>

<strong>Risposta corretta:</strong> C

<strong>Feedback risposta corretta:</strong>
<p>‚úì <strong>Perfetto!</strong> Il <strong>2 agosto 2026</strong> √® la data cruciale per sistemi ad alto rischio (HR, credit scoring, valutazione lavoratori). Hai 18 mesi da oggi per prepararti.</p>

<strong>Feedback risposta errata:</strong>
<p>‚úó <strong>Non corretto.</strong> La data chiave √® il <strong>2 agosto 2026</strong>. Prima (febbraio/agosto 2025) entrano in vigore solo divieti e obblighi per fornitori GPAI. Per deployer di sistemi ad alto rischio, il 2 agosto 2026 √® la deadline. <strong>Rivedi sezione 1.3 - Timeline.</strong></p>

<hr>

<h3>Domanda 4 di 6</h3>

<strong>Quale funzione aziendale gestisce un sistema ad alto rischio?</strong>

<strong>Opzioni:</strong>
<ul>
<li>A) Marketing che usa ChatGPT per scrivere post social</li>
<li>B) HR che usa software AI per screening CV senza supervisione umana</li>
<li>C) IT che usa AI per previsioni vendite interne</li>
<li>D) Customer service che usa chatbot informativo sul sito</li>
</ul>

<strong>Risposta corretta:</strong> B

<strong>Feedback risposta corretta:</strong>
<p>‚úì <strong>Corretto!</strong> Il recruitment automatizzato √® ad alto rischio perch√© impatta il diritto al lavoro. Senza supervisione umana, viola l'AI Act. HR deve implementare human oversight obbligatorio.</p>

<strong>Feedback risposta errata:</strong>
<p>‚úó <strong>Non corretto.</strong> Il recruitment automatizzato (screening CV con AI) √® classificato <strong>alto rischio</strong> perch√© influisce sui diritti fondamentali delle persone (accesso al lavoro). Gli altri esempi sono rischio limitato o minimo. <strong>Rivedi sezione 1.2 - Sistemi ad Alto Rischio e sezione 1.4 - Implicazioni HR.</strong></p>

<hr>

<h3>Domanda 5 di 6 (Scenario-based)</h3>

<strong>Scenario:</strong> Un'azienda di e-commerce usa un chatbot sul sito per assistenza clienti. Il chatbot risponde a domande su spedizioni, resi, disponibilit√† prodotti. A volte il chatbot non riesce a rispondere e passa la conversazione a un operatore umano.

<strong>Cosa deve fare l'azienda per essere conforme all'AI Act?</strong>

<strong>Opzioni:</strong>
<ul>
<li>A) Nulla, i chatbot non sono regolati</li>
<li>B) Condurre una DPIA prima di attivare il chatbot</li>
<li>C) Informare l'utente che sta interagendo con un assistente virtuale AI</li>
<li>D) Implementare human oversight per ogni risposta del chatbot</li>
</ul>

<strong>Risposta corretta:</strong> C

<strong>Feedback risposta corretta:</strong>
<p>‚úì <strong>Esatto!</strong> Il chatbot √® rischio limitato. L'obbligo principale √® <strong>trasparenza</strong>: devi avvisare l'utente che sta parlando con un'AI. Non servono DPIA o supervisione umana costante per chatbot informativi.</p>

<strong>Feedback risposta errata:</strong>
<p>‚úó <strong>Non corretto.</strong> Un chatbot per assistenza clienti √® classificato <strong>rischio limitato</strong>. L'obbligo principale √® <strong>trasparenza</strong>: informare l'utente che sta interagendo con un assistente AI. DPIA e human oversight sono obbligatori solo per sistemi ad alto rischio. <strong>Rivedi sezione 1.2 - Sistemi a Rischio Limitato e sezione 1.4 - Customer Service.</strong></p>

<hr>

<h3>Domanda 6 di 6 (Vero/Falso)</h3>

<strong>Affermazione:</strong> "Le PMI che usano solo ChatGPT o Microsoft Copilot per attivit√† interne (scrivere report, analizzare dati) non hanno nessun obbligo dall'AI Act."

<strong>Vero o Falso?</strong>

<strong>Risposta corretta:</strong> Falso

<strong>Feedback risposta corretta:</strong>
‚úì <strong>Corretto!</strong> Anche per usi interni di GPAI, le PMI sono considerate deployer e devono rispettare obblighi base: tenere un registro dei sistemi AI usati, garantire trasparenza se l'AI genera contenuti pubblici o decisioni su persone, e formare il personale sui limiti dell'AI. Gli obblighi sono leggeri, ma esistono.

<strong>Feedback risposta errata:</strong>
‚úó <strong>Non corretto. L'affermazione √® FALSA.</strong> Anche se usi solo ChatGPT/Copilot internamente, sei comunque un deployer AI. Hai obblighi minimi ma importanti:
<ul>
<li>Tenere un registro dei tool AI usati</li>
<li>Formare i dipendenti su uso responsabile</li>
<li>Garantire trasparenza se l'AI genera contenuti pubblici o decisioni</li>
<li>Valutare rischi se usi AI per decisioni su persone</li>
</ul>

<strong>Rivedi sezione 1.1 e 1.2 per comprendere gli obblighi base per deployer.</strong>

<hr>

<h2>Riepilogo Modulo 1</h2>

<strong>Hai imparato:</strong>
<ul>
<li>‚úì <strong>Cos'√® l'AI Act</strong> e perch√© regola l'intelligenza artificiale in Europa</li>
<li>‚úì <strong>La differenza tra fornitore e deployer</strong> (la maggior parte delle PMI √® deployer)</li>
<li>‚úì <strong>Le 4 categorie di sistemi AI</strong>: proibiti üî¥, alto rischio üü†, GPAI üü°, rischio limitato/minimo üü¢</li>
<li>‚úì <strong>Le date chiave</strong>: 2 agosto 2026 √® la deadline per sistemi ad alto rischio (HR, credit scoring)</li>
<li>‚úì <strong>Le implicazioni concrete per la tua funzione</strong> (Marketing, HR, Customer Service, IT, Legal)</li>
</ul>

<strong>Competenze acquisite:</strong>
<ul>
<li>‚óã Distinguere tra sistemi AI permessi, regolati, e proibiti</li>
<li>‚óã Identificare quali tool AI usi nella tua funzione rientrano nell'AI Act</li>
<li>‚óã Conoscere la timeline di conformit√† e quando agire</li>
</ul>

<strong>Prossimo modulo:</strong>
<p>Nel <strong>Modulo 2</strong> esplorerai <strong>5 scenari concreti di uso AI</strong> nelle PMI italiane. Imparerai a classificare ciascun caso nelle categorie AI Act e a identificare i requisiti minimi di conformit√†. Userai un framework decisionale pratico applicabile ai tuoi sistemi aziendali.</p>

<strong>Collegamenti utili:</strong>
<ul>
<li><a href="https://eur-lex.europa.eu/" target="_blank">Testo ufficiale EU AI Act (EUR-Lex)</a></li>
<li><a href="https://www.garanteprivacy.it/" target="_blank">Guida Garante Privacy italiano su AI e GDPR</a></li>
<li><a href="https://ec.europa.eu/ai" target="_blank">FAQ Commissione Europea su AI Act</a></li>
</ul>

<hr>

<strong>Fine Modulo 1</strong>

        </div>

        <div class="navigation">
  <span></span>
  <div class="nav-center">
    <a href="index.html" class="nav-button">üìö Indice</a>
  </div>
  <a href="modulo2.html" class="nav-button">Successivo: Modulo 2: Mappa dei casi d'uso e rischio ‚Üí</a>
</div>

    </div>

    <script>
        // Initialize SCORM
        window.addEventListener('load', function() {
            initializeSCORM();
        });

        window.addEventListener('beforeunload', function() {
            completeSCORM();
        });
    </script>
</body>
</html>